#version 460
#extension GL_ARB_separate_shader_objects : enable
#extension GL_ARB_shading_language_420pack : enable
#extension GL_GOOGLE_include_directive : require

#define NUM_FILTER 9

layout(local_size_x = 32, local_size_y = 16, local_size_z = 1) in;

layout(set = 0, binding = 1) uniform UniformFilterData {
    vec2 noiseScale;
} filterData;

layout(set = 0, binding = 2) uniform UniformJitterData {
    vec2 jitter;
} jitterData;

layout(set=0, binding=4) uniform sampler2D inDepth;
layout(set=0, binding=5) uniform sampler2D inNormal;
layout(set=0, binding=6) uniform sampler2D inMaterial;
layout(set=0, binding=7) uniform sampler2D LightingMap;
layout(set=0, binding=8) uniform sampler2D SSRHitsMap;
layout(set=0, binding=9) uniform sampler2D SSRHitsMask;
layout(set=0, binding=10) uniform sampler2D blueNoise;

layout(set=0, binding=11) writeonly uniform image2D ReflectionColorMap;

#include <Misc/Camera.glsl>
#include <Misc/Utils.glsl>
#include <Misc/Constants.glsl>

float evalGGX(float ggxAlpha, float NdotH)
{
    float a2 = ggxAlpha * ggxAlpha;
    float d = ((NdotH * a2 - NdotH) * NdotH + 1.0f);
    return a2 / (M_PI * d * d);
}

float Vis_SmithJointApprox(float NdotL, float NdotV, float roughness)
{
    float a = roughness * roughness;
    float Vis_SmithV = NdotL * (NdotV * (1 - a) + a);
    float Vis_SmithL = NdotV * (NdotL * (1 - a) + a);
    return 0.5 / (Vis_SmithV + Vis_SmithL);
}

float Luminance(vec3 color) {
    return dot(color, vec3(0.2126, 0.7152, 0.0722));
}

const vec2 offset[9] = {vec2(-2.0, -2.0), vec2(0.0, -2.0), vec2(2.0, -2.0), vec2(-2.0, 0.0), vec2(0.0, 0.0), vec2(2.0, 0.0), vec2(-2.0, 2.0), vec2(0.0, 2.0), vec2(2.0, 2.0)};

void main() 
{
    ivec2 pixel = ivec2(gl_GlobalInvocationID.xy);
    if(pixel.x >= camera.pixelSize.x || pixel.y >= camera.pixelSize.y)
        return;

    int viewIndex = pixel.x < (camera.pixelSize.x / 2) ? 0 : 1;
    vec2 screenUV = (vec2(pixel) + vec2(0.5f)) * camera.pixelSize.zw;
    vec3 originWS = StereoWorldSpacePosAtScreenUV(screenUV);
    vec3 eyeWS = camera.cameraStereoPosition[viewIndex].xyz;

    vec3 eyeRayWS = normalize(eyeWS - originWS);

    vec3 normalWS = texture(inNormal, screenUV).xyz;
    vec3 normalVS = normalize(mat3(transpose(inverse(camera.stereoView[viewIndex]))) * normalWS);

    float roughness = texture(inMaterial, screenUV).g;
    vec2 noise = texture(blueNoise, (screenUV + jitterData.jitter) * filterData.noiseScale).rg * 2.0f - 1.0f;
    mat2 rotation = mat2(noise.x, noise.y, -noise.y, -noise.x);

    float totalWeight = 0.0f;
    vec4 ReflectionColor = vec4(0.0f);

    for(int i = 0; i < NUM_FILTER; i++) {
        vec2 offsetUV = rotation * offset[i] * camera.pixelSize.zw;
        vec2 sampleUV = screenUV;

        vec4 hitInfo = texture(SSRHitsMap, sampleUV); // xy: hitUV, z: hitDepth, w: pdf
        vec3 hitPosWS = StereoWorldSpacePosAtScreenUV(hitInfo.xy);

        if(hitInfo.xy == vec2(-1.0f)) continue;

        vec3 reflectRayWS = hitPosWS - originWS;

        vec3 H = normalize(eyeRayWS + reflectRayWS);
        float NdotH = clamp(dot(normalWS, H), 0.0f, 1.0f);
        float NdotV = clamp(dot(normalWS, eyeRayWS), 0.0f, 1.0f);
        float NdotL = clamp(dot(normalWS, reflectRayWS), 0.0f, 1.0f);

        float brdf = max(0.0f, evalGGX(roughness, NdotH) * Vis_SmithJointApprox(NdotL, NdotV, roughness));
        float pdf = max(1e-5, hitInfo.w);

        float weight = brdf * NdotL / pdf;
        vec4 sampleColor = vec4(texture(LightingMap, hitInfo.xy).xyz, texture(SSRHitsMask, sampleUV).x);
        sampleColor.rgb /= 1 + Luminance(sampleColor.rgb);

        ReflectionColor += sampleColor * weight;
        totalWeight += weight;
    }

    ReflectionColor /= totalWeight;
    ReflectionColor.rgb /= 1 - Luminance(ReflectionColor.rgb);
    ReflectionColor.rgb = max(vec3(1e-5), ReflectionColor.rgb);

    imageStore(ReflectionColorMap, pixel, ReflectionColor);
}